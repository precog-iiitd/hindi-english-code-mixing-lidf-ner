{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pycrfsuite\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ner.final.features', 'r') as fp:\n",
    "    uniqueTweets = joblib.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35374"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(lambda x : len(x), uniqueTweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = []\n",
    "\n",
    "for tw in uniqueTweets:\n",
    "    for token in tw:\n",
    "        lang.append(token[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'en': 13860, 'hi': 11391, 'rest': 10123})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2079"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniqueTweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asciiPercentage(s):\n",
    "\tcount = 0.\n",
    "\tfor char in s:\n",
    "\t\tif ord(char) < 128:\n",
    "\t\t\tcount += 1\n",
    "\treturn count/len(s)\n",
    "\n",
    "def vowelPercentage(s):\n",
    "\tvowels = \"aeiou\"\n",
    "\tcount = 0.\n",
    "\tfor char in s:\n",
    "\t\tif char in vowels:\n",
    "\t\t\tcount += 1\n",
    "\treturn count/len(s)\n",
    "\n",
    "def capPercentage(s):\n",
    "    count = 0.\n",
    "    for ch in s:\n",
    "        if ch.isupper():\n",
    "            count += 1\n",
    "    return count / len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 #MaheshBabu Gully\n",
      "1 rest en\n",
      "2 # A\n",
      "3 0.0 0.6312\n",
      "4 B-NP B-NP\n",
      "5 X ADJ\n",
      "6  UNK\n",
      "7  Gully\n",
      "8 O O\n"
     ]
    }
   ],
   "source": [
    "# [TOKEN, LANG, EPOS, EPOSSCORE, CHUNK, POS, HPOS, NORM, LABEL]\n",
    "\n",
    "for i in range(len(uniqueTweets[0][0])):\n",
    "    print i, uniqueTweets[-1][0][i], uniqueTweets[0][0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordShape(token):\n",
    "    wordTransform = ''\n",
    "    \n",
    "    for ch in token:\n",
    "        if ch.isalpha():\n",
    "            if ch.isupper():\n",
    "                wordTransform += 'X'\n",
    "            if ch.islower():\n",
    "                wordTransform += 'x'\n",
    "        else:\n",
    "            try:\n",
    "                int(ch)\n",
    "                wordTransform += 'O'\n",
    "            except ValueError:\n",
    "                wordTransform += ch\n",
    "    return wordTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "\n",
    "    # feature vector\n",
    "    # [TOKEN, LANG, EPOS, EPOSSCORE, CHUNK, POS, HPOS, NORM, LABEL]\n",
    "    \n",
    "    # Tweet level features\n",
    "    allTokens = [sent[k][0] for k in range(len(sent))]\n",
    "    \n",
    "    tweetTitlePer = 0.\n",
    "    for word in allTokens:\n",
    "        if word.istitle():\n",
    "            tweetTitlePer += 1\n",
    "    tweetTitlePer /= len(allTokens)\n",
    "    \n",
    "    tweetCapPer = 0.\n",
    "    \n",
    "    for word in allTokens:\n",
    "        tweetCapPer += capPercentage(word)\n",
    "    tweetCapPer /= len(allTokens)\n",
    "    \n",
    "    word = sent[i][0]\n",
    "    wordShape = getWordShape(word)\n",
    "    cleanWord = ''.join([ch for ch in word if ch in 'asdfghjklqwertyuiopzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM'])\n",
    "    normalizedWord = cleanWord.lower()\n",
    "    \n",
    "    lang = sent[i][1]\n",
    "    anyCap = any(char.isupper() for char in word)\n",
    "    allCap = all(char.isupper() for char in word)\n",
    "    hasSpecial = any( ord(char) > 32 and ord(char) < 65 for char in word)\n",
    "    \n",
    "    \n",
    "    hashTag = word[0] == '#'\n",
    "    mention = word[0] == '@'\n",
    "\n",
    "    epos = sent[i][2]\n",
    "    chunk = sent[i][4]\n",
    "    pos = sent[i][5]\n",
    "    \n",
    "    \n",
    "    features = {\n",
    "                'token' : word,\n",
    "                'wordShape' : wordShape,\n",
    "                'cleanWord' : cleanWord,\n",
    "                'normalizedWord' : normalizedWord,\n",
    "                \n",
    "                'lang' : lang,\n",
    "                'isTitle' : word.istitle(),\n",
    "                'wordLength' : len(word),\n",
    "                'anyCap' : anyCap, \n",
    "                'allCap' : word.isupper(),\n",
    "                'hasSpecial' : hasSpecial, \n",
    "                'asciiPer' : asciiPercentage(word),\\\n",
    "                \n",
    "                'epos' : epos, \n",
    "                'hashtag' : hashTag, \n",
    "                'mention' : mention,\n",
    "                'tweetCapPer' : tweetCapPer,\n",
    "                'tweetTitlePer' : tweetTitlePer,\n",
    "               }\n",
    "    \n",
    "    features['suffix5'] = word[-5:]\n",
    "    features['prefix5'] = word[:5]\n",
    "    features['suffix4'] = word[-4:]\n",
    "    features['prefix4'] = word[:4]\n",
    "    features['suffix3'] = word[-3:]\n",
    "    features['prefix3'] = word[:3]\n",
    "    features['suffix2'] = word[-2:]\n",
    "    features['prefix2'] = word[:2]\n",
    "    features['suffix1'] = word[-1:]\n",
    "    features['prefix1'] = word[:1]  \n",
    "    \n",
    "    if i > 0:\n",
    "        word1 = sent[i - 1][0]\n",
    "        lang1 = sent[i - 1][1]\n",
    "\n",
    "        features['-1:word.lang'] = lang1\n",
    "        features['-1:word.lower'] = word1.lower()\n",
    "        features['-1:word.epos'] = sent[i - 1][2]\n",
    "        features['-1.BOS'] = False\n",
    "\n",
    "    else:\n",
    "\n",
    "        features['-1:word.lang'] = ''\n",
    "        features['-1:word.lower'] = ''\n",
    "        features['-1:word.epos'] = ''\n",
    "        features['-1:BOS'] = True\n",
    "\n",
    "    if i < len(sent) - 1:\n",
    "\n",
    "        word1 = sent[i + 1][0]\n",
    "        lang1 = sent[i + 1][1]\n",
    "\n",
    "        features['+1:word.lang'] = lang1\n",
    "        features['+1:word.lower'] = word1.lower()\n",
    "        features['+1:word.epos'] = sent[i + 1][2]\n",
    "        features['+1:EOS'] = False\n",
    "    else:\n",
    "        features['+1:word.lang'] = ''\n",
    "        features['+1:word.lower'] = ''\n",
    "        features['+1:word.epos'] = ''\n",
    "        features['+1:EOS'] = True\n",
    "        \n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "\tfeatures = []\n",
    "\n",
    "\tfor i in range(len(sent)):\n",
    "\t\tfeatures.append(word2features(sent, i))\n",
    "\n",
    "\treturn features\n",
    "\n",
    "def sent2labels(sent):\n",
    "    allLabels = []\n",
    "\n",
    "    for i in sent:\n",
    "        currLabel = i[-1]\n",
    "        if currLabel == '@' or currLabel == 'B-@':\n",
    "            currLabel = 'O'\n",
    "        else:\n",
    "            pass\n",
    "        allLabels.append(currLabel)\n",
    "            \n",
    "    return allLabels\n",
    "\n",
    "def sent2tokens(sent):\n",
    "\n",
    "\tallTokens = []\n",
    "\n",
    "\tfor i in sent:\n",
    "\t\tallTokens.append(i[0])\n",
    "\n",
    "\treturn allTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation 0 for 0.01 0.01\n",
      "training\n",
      "testing\n",
      " CRF Classification\n",
      "cross validation 1 for 0.01 0.01\n",
      "training\n",
      "testing\n",
      " CRF Classification\n",
      "cross validation 2 for 0.01 0.01\n",
      "training\n",
      "testing\n",
      " CRF Classification\n",
      "cross validation 3 for 0.01 0.01\n",
      "training\n",
      "testing\n",
      " CRF Classification\n",
      "cross validation 4 for 0.01 0.01\n",
      "training\n",
      "testing\n",
      " CRF Classification\n",
      "0.01 0.01\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "B-ORGANISATION       0.89      0.62      0.73       375\n",
      "      B-PERSON       0.81      0.70      0.75      1638\n",
      "       B-PLACE       0.82      0.69      0.75       738\n",
      "I-ORGANISATION       0.66      0.33      0.44       111\n",
      "      I-PERSON       0.79      0.75      0.77       701\n",
      "       I-PLACE       0.66      0.46      0.54       178\n",
      "             O       0.97      0.99      0.98     31561\n",
      "\n",
      "   avg / total       0.95      0.96      0.95     35302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c1 in [.01]:\n",
    "    for c2 in [.01]:\n",
    "    \n",
    "        k = 5\n",
    "\n",
    "        chunk = len(uniqueTweets)/k\n",
    "        results = []\n",
    "\n",
    "        allTestPredictions = []\n",
    "        allTestGroundTruth = []\n",
    "        allTokens = []\n",
    "        \n",
    "        for i in range(k):\n",
    "\n",
    "            print \"cross validation\", i, 'for', c1, c2\n",
    "\n",
    "            test_sents = uniqueTweets[i * chunk : (i + 1) * chunk]\n",
    "            train_sents = uniqueTweets[:i * chunk] + uniqueTweets[(i + 1) * chunk:]\n",
    "\n",
    "            X_train = [sent2features(s) for s in train_sents]\n",
    "            y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "            X_test = [sent2features(s) for s in test_sents]\n",
    "            y_test = [sent2labels(s) for s in test_sents]\n",
    "            X_test_tokens = []\n",
    "            \n",
    "            trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "            for xseq, yseq in zip(X_train, y_train):\n",
    "                trainer.append(xseq, yseq)\n",
    "\n",
    "            trainer.set_params({\n",
    "                'c1': c1,   # coefficient for L1 penalty\n",
    "                'c2': c2,  # coefficient for L2 penalty\n",
    "                'max_iterations': 10200,  # stop earlier\n",
    "\n",
    "                # include transitions that are possible, but not observed\n",
    "                'feature.possible_transitions': True,\n",
    "                'feature.possible_states' : False\n",
    "            })\n",
    "\n",
    "            print \"training\"\n",
    "            trainer.train('ner_t_f' + str(i))\n",
    "\n",
    "\n",
    "            print \"testing\"\n",
    "            tagger = pycrfsuite.Tagger()\n",
    "            tagger.open('ner_t_f' + str(i))\n",
    "\n",
    "            y_pred = []\n",
    "\n",
    "            for xseq in X_test:\n",
    "                y_pred.append(tagger.tag(xseq))\n",
    "\n",
    "\n",
    "            \"\"\" CRF based classification \"\"\"\n",
    "\n",
    "            predictedLabels = []\n",
    "            correctLabels = []\n",
    "            xTokens = []\n",
    "            \n",
    "            for i in y_pred:\n",
    "                for j in i:\n",
    "                    predictedLabels.append(j)\n",
    "\n",
    "            for i in y_test:\n",
    "                for j in i:\n",
    "                    correctLabels.append(j)\n",
    "\n",
    "            for i in X_test:\n",
    "                for j in i:\n",
    "                    xTokens.append(j['token'])\n",
    "            allTestPredictions += predictedLabels\n",
    "            allTestGroundTruth += correctLabels\n",
    "            print \"\"\" CRF Classification\"\"\"\n",
    "            \n",
    "        print c1, c2\n",
    "        print classification_report(allTestGroundTruth, allTestPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification result, running the conll eval script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fp = open('crf.classify.compare', 'w')\n",
    "\n",
    "mark = 0\n",
    "for i in range(k):\n",
    "\n",
    "    test_sents = uniqueTweets[i * chunk : (i + 1) * chunk]\n",
    "    \n",
    "    for sent in test_sents:\n",
    "        labels = [token[-1] for token in sent]\n",
    "        for _ in range(len(labels) - 1):\n",
    "            if labels[_] == 'O' and labels[_ + 1][:2] == 'I-':\n",
    "                for tt in sent:\n",
    "                    print tt\n",
    "                print '\\n'\n",
    "                    \n",
    "                \n",
    "        for token in sent:\n",
    "            fp.write('_' + ' ' + allTestGroundTruth[mark] + ' ' + allTestPredictions[mark] + '\\n')\n",
    "            mark += 1\n",
    "            \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 35302 tokens with 2754 phrases; found: 2291 phrases; correct: 1799.\r\n",
      "accuracy:  95.71%; precision:  78.52%; recall:  65.32%; FB1:  71.32\r\n",
      "     ORGANISATION: precision:  87.12%; recall:  61.33%; FB1:  71.99  264\r\n",
      "           PERSON: precision:  76.99%; recall:  66.14%; FB1:  71.15  1408\r\n",
      "            PLACE: precision:  78.35%; recall:  65.54%; FB1:  71.38  619\r\n"
     ]
    }
   ],
   "source": [
    "! ./conlleval < crf.classify.compare "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation results, running the conll eval script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   B-ENTITY       0.89      0.74      0.81      2751\n",
      "   I-ENTITY       0.82      0.70      0.76       990\n",
      "          O       0.97      0.99      0.98     31561\n",
      "\n",
      "avg / total       0.96      0.96      0.96     35302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(allTestGroundTruth)):\n",
    "    if allTestGroundTruth[i] == 'O':\n",
    "        pass\n",
    "    else:\n",
    "        allTestGroundTruth[i] = allTestGroundTruth[i][:2] + 'ENTITY'\n",
    "    if allTestPredictions[i] == 'O':\n",
    "        pass\n",
    "    else:\n",
    "        allTestPredictions[i] = allTestPredictions[i][:2] + 'ENTITY'\n",
    "        \n",
    "print classification_report(allTestGroundTruth, allTestPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation 0 for 0.01 0.01\n",
      "cross validation 1 for 0.01 0.01\n",
      "cross validation 2 for 0.01 0.01\n",
      "cross validation 3 for 0.01 0.01\n",
      "cross validation 4 for 0.01 0.01\n"
     ]
    }
   ],
   "source": [
    "fp = open('crf.segment.compare', 'w')\n",
    "\n",
    "mark = 0\n",
    "for i in range(k):\n",
    "\n",
    "    print \"cross validation\", i, 'for', c1, c2\n",
    "\n",
    "    test_sents = uniqueTweets[i * chunk : (i + 1) * chunk]\n",
    "    \n",
    "    for sent in test_sents:\n",
    "        for token in sent:\n",
    "            fp.write(token[0] + ' ' + allTestGroundTruth[mark] + ' ' + allTestPredictions[mark] + '\\n')\n",
    "            mark += 1\n",
    "            \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 35302 tokens with 2751 phrases; found: 2290 phrases; correct: 1924.\r\n",
      "accuracy:  96.29%; precision:  84.02%; recall:  69.94%; FB1:  76.33\r\n",
      "           ENTITY: precision:  84.02%; recall:  69.94%; FB1:  76.33  2290\r\n"
     ]
    }
   ],
   "source": [
    "! ./conlleval < crf.segment.compare "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
