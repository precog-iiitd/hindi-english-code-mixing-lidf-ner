{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import json\n",
    "import ast\n",
    "import joblib\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import editdistance\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('guptaEtAl.tokenised', 'r') as fp:\n",
    "    data = fp.readlines()\n",
    "    \n",
    "currTweet = []\n",
    "allTweets = []\n",
    "\n",
    "for i in range(len(data[:])):\n",
    "    if len(data[i].split('\\t')) == 3:\n",
    "        currTweet.append(data[i].split('\\t')[0:2])\n",
    "    else:\n",
    "        allTweets.append(currTweet)\n",
    "        currTweet = []\n",
    "if len(currTweet) != 0:\n",
    "    allTweets.append(currTweet)\n",
    "    currTweet = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English mapping for transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/kushagras/work/transliterationData/romanToDevanagiri/englishMap', 'r') as fp:\n",
    "    EnglishMap = fp.read()\n",
    "    EnglishMap = ast.literal_eval(EnglishMap)\n",
    "\n",
    "    revEnglishMap = [0 for i in range(len(EnglishMap))]\n",
    "    for key in EnglishMap:\n",
    "        revEnglishMap[EnglishMap[key]] = key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(allTweets)):\n",
    "    for j in range(len(allTweets[i])):\n",
    "        \n",
    "        # Create english encoding of clean text\n",
    "        cleanText = ''.join([ch for ch in allTweets[i][j][0].lower() if ch in EnglishMap])\n",
    "        englishEncoding = [str(EnglishMap[ch]) for ch in cleanText]\n",
    "        allTweets[i][j] += [cleanText, englishEncoding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original       : mee too but aaj jaldi chalke dekhte hai :P\n",
      "Cleaned        : mee too but aaj jaldi chalke dekhte hai p\n"
     ]
    }
   ],
   "source": [
    "tweetID = 0\n",
    "\n",
    "print 'Original       :', ' '.join(map(lambda x : x[0], allTweets[tweetID]))\n",
    "print 'Cleaned        :', ' '.join(map(lambda x : x[2], allTweets[tweetID]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mee', 'en', 'mee', ['12', '4', '4']]\n"
     ]
    }
   ],
   "source": [
    "# 0 -> Original Token\n",
    "# 1 -> Language\n",
    "# 2 -> Clean token\n",
    "# 3 -> Roman encoding\n",
    "\n",
    "print allTweets[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write encodings to file for transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open('wordsToTransliterate.txt', 'w')\n",
    "\n",
    "for tweet in allTweets:\n",
    "    for token in tweet:\n",
    "        englishEncoding = token[3]\n",
    "        if len(englishEncoding) != 0:\n",
    "            fp.write(' '.join(englishEncoding) + '\\n')\n",
    "\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "===\n",
    "\n",
    "# Run transliterator\n",
    "\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "devanagariChars = [u'\\u0900', u'\\u0901', u'\\u0902', u'\\u0903', u'\\u0904', u'\\u0905', u'\\u0906', u'\\u0907', u'\\u0908', u'\\u0909', u'\\u090a', u'\\u090b', u'\\u090c', u'\\u090d', u'\\u090e', u'\\u090f', u'\\u0910', u'\\u0911', u'\\u0912', u'\\u0913', u'\\u0914', u'\\u0915', u'\\u0916', u'\\u0917', u'\\u0918', u'\\u0919', u'\\u091a', u'\\u091b', u'\\u091c', u'\\u091d', u'\\u091e', u'\\u091f', u'\\u0920', u'\\u0921', u'\\u0922', u'\\u0923', u'\\u0924', u'\\u0925', u'\\u0926', u'\\u0927', u'\\u0928', u'\\u0929', u'\\u092a', u'\\u092b', u'\\u092c', u'\\u092d', u'\\u092e', u'\\u092f', u'\\u0930', u'\\u0931', u'\\u0932', u'\\u0933', u'\\u0934', u'\\u0935', u'\\u0936', u'\\u0937', u'\\u0938', u'\\u0939', u'\\u093a', u'\\u093b', u'\\u093c', u'\\u093d', u'\\u093e', u'\\u093f', u'\\u0940', u'\\u0941', u'\\u0942', u'\\u0943', u'\\u0944', u'\\u0945', u'\\u0946', u'\\u0947', u'\\u0948', u'\\u0949', u'\\u094a', u'\\u094b', u'\\u094c', u'\\u094d', u'\\u094e', u'\\u094f', u'\\u0950', u'\\u0951', u'\\u0952', u'\\u0953', u'\\u0954', u'\\u0955', u'\\u0956', u'\\u0957', u'\\u0958', u'\\u0959', u'\\u095a', u'\\u095b', u'\\u095c', u'\\u095d', u'\\u095e', u'\\u095f', u'\\u0960', u'\\u0961', u'\\u0962', u'\\u0963', u'\\u0964', u'\\u0965', u'\\u0966', u'\\u0967', u'\\u0968', u'\\u0969', u'\\u096a', u'\\u096b', u'\\u096c', u'\\u096d', u'\\u096e', u'\\u096f', u'\\u0970', u'\\u0971', u'\\u0972', u'\\u0973', u'\\u0974', u'\\u0975', u'\\u0976', u'\\u0977', u'\\u0978', u'\\u0979', u'\\u097a', u'\\u097b', u'\\u097c', u'\\u097d', u'\\u097e', u'\\u097f']\n",
    "\n",
    "with open('/home/kushagras/work/transliterationData/romanToDevanagiri/hindiMap', 'r') as fp:\n",
    "    HindiMap = fp.read()\n",
    "    HindiMap = ast.literal_eval(HindiMap)\n",
    "\n",
    "    revHindiMap = [0 for i in range(len(HindiMap))]\n",
    "    for key in HindiMap:\n",
    "        revHindiMap[HindiMap[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wordsTransliterated.txt', 'r') as fp:\n",
    "    transliteratedEncoding = fp.readlines()\n",
    "\n",
    "transliteratedText  = []\n",
    "\n",
    "for i in range(len(transliteratedEncoding)):\n",
    "    transliteratedEncoding[i] = transliteratedEncoding[i].strip('\\n').split(' ')\n",
    "    string = ''\n",
    "    for ch in transliteratedEncoding[i]:\n",
    "        if ch != '':\n",
    "            string += devanagariChars[int(ch)]\n",
    "    transliteratedText.append(string)\n",
    "    \n",
    "mark = 0\n",
    "\n",
    "for i in range(len(allTweets[:])):\n",
    "    for j in range(len(allTweets[i])):\n",
    "        englishEncoding = allTweets[i][j][3]\n",
    "        if len(englishEncoding) != 0:\n",
    "            allTweets[i][j] += [transliteratedEncoding[mark], transliteratedText[mark]]\n",
    "            mark += 1\n",
    "        else:\n",
    "            allTweets[i][j] += [[], \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original       : agar attendance lag gayi toh badhiya .\n",
      "Cleaned        : agar attendance lag gayi toh badhiya \n",
      "Transliterated : अगर एटेंडेन्स लग गयी तो बढ़िया \n"
     ]
    }
   ],
   "source": [
    "tweetID = 3\n",
    "\n",
    "print 'Original       :', ' '.join(map(lambda x : x[0], allTweets[tweetID]))\n",
    "print 'Cleaned        :', ' '.join(map(lambda x : x[2], allTweets[tweetID]))\n",
    "print 'Transliterated :', ' '.join(map(lambda x : x[5], allTweets[tweetID]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lang model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "import sys\n",
    "import gc\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import keras.layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load encoding maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 30\n",
    "\n",
    "with open('/home/kushagras/work/transliterationData/romanToDevanagiri/hindiMap', 'r') as fp:\n",
    "    hindiMap = fp.read()\n",
    "    hindiMap = ast.literal_eval(hindiMap)\n",
    "\n",
    "    revHindiMap = [0 for i in range(len(hindiMap))]\n",
    "    for key in hindiMap:\n",
    "        revHindiMap[hindiMap[key]] = key\n",
    "        \n",
    "with open('/home/kushagras/work/transliterationData/romanToDevanagiri/englishMap', 'r') as fp:\n",
    "    englishMap = fp.read()\n",
    "    englishMap = ast.literal_eval(englishMap)\n",
    "\n",
    "    revEnglishMap = [0 for i in range(len(englishMap))]\n",
    "    for key in englishMap:\n",
    "        revEnglishMap[englishMap[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEnglishModel(rev = False):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(128, input_shape = (maxlen, len(englishMap)), return_sequences = True))\n",
    "    if rev == True:\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "    else:\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "    model.add(keras.layers.Dropout(0.7))\n",
    "\n",
    "    model.add(LSTM(128))\n",
    "    if rev == True:\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "    else:\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.7))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    if rev == True:\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "    else:\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.7))\n",
    "\n",
    "    model.add(Dense(len(englishMap)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def getHindiModel(rev = False):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(128, input_shape = (maxlen, len(hindiMap)), return_sequences = True))\n",
    "    if rev == True:\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "    else:\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.7))\n",
    "\n",
    "    model.add(LSTM(128))\n",
    "    if rev == True:\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "    else:\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.7))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    if rev == True:\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "    else:\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.7))\n",
    "\n",
    "    model.add(Dense(len(hindiMap)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindiModel = getHindiModel(rev = True)\n",
    "englishModel = getEnglishModel(rev = True)\n",
    "\n",
    "hindiModelFile   = '/home/kushagras/work/languageModels/hindi/models/99_rev'\n",
    "englishModelFile = '/home/kushagras/work/languageModels/english/models/99_rev'\n",
    "\n",
    "hindiModel.load_weights(hindiModelFile)\n",
    "englishModel.load_weights(englishModelFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get probabilitites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "romanTokens = []\n",
    "devanagariTokens = []\n",
    "\n",
    "for tweet in allTweets:\n",
    "    for token in tweet:\n",
    "        if len(token[3]):\n",
    "            romanTokens.append(token[3])\n",
    "            devanagariTokens.append(token[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding ...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del romanIn\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del devanagiriIn\n",
    "except:\n",
    "    pass\n",
    "\n",
    "romanIn = np.zeros((len(romanTokens), maxlen, len(englishMap)))\n",
    "devanagiriIn = np.zeros((len(devanagariTokens), maxlen, len(hindiMap)))\n",
    "\n",
    "print \"Encoding ...\"\n",
    "sys.stdout.flush()\n",
    "\n",
    "for j in range(len(romanTokens)):\n",
    "    for k in range(len(romanTokens[j]) - 1):\n",
    "        romanIn[j, k, int(romanTokens[j][k])] = 1\n",
    "        \n",
    "for j in range(len(devanagariTokens)):\n",
    "    for k in range(len(devanagariTokens[j]) - 1):\n",
    "        devanagiriIn[j, k, int(devanagariTokens[j][k])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishProbabilities = englishModel.predict_proba(romanIn, batch_size = 1024)\n",
    "hindiProbabilities  = hindiModel.predict_proba(devanagiriIn, batch_size = 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add probabilities to the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark = 0\n",
    "\n",
    "for i in range(len(allTweets)):\n",
    "    for j in range(len(allTweets[i])):\n",
    "        if len(allTweets[i][j][3]):\n",
    "            allTweets[i][j].append(englishProbabilities[mark].tolist())\n",
    "            allTweets[i][j].append(hindiProbabilities[mark].tolist())\n",
    "            mark += 1\n",
    "        else:\n",
    "            allTweets[i][j].append(np.zeros_like(englishProbabilities[0]))\n",
    "            allTweets[i][j].append(np.zeros_like(hindiProbabilities[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 -> Original Token\n",
    "# 1 -> Language\n",
    "# 2 -> Clean token\n",
    "# 3 -> Roman encoding\n",
    "# 4 -> Devanagiri encoding\n",
    "# 5 -> Hindi word\n",
    "# 6 -> englishProbs\n",
    "# 7 -> hindiProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOtherFeatures = 4\n",
    "\n",
    "\n",
    "def probFeatureExtractor(token):\n",
    "    \n",
    "    # 26 eng + 128 hin + 3 others\n",
    "    \n",
    "    features = np.concatenate((token[6], token[7])).tolist()\n",
    "    \n",
    "    return features\n",
    "    \n",
    "def otherFeatureExtractor(token):\n",
    "    \n",
    "    # other features\n",
    "    features = []\n",
    "    \n",
    "    # 1. Fraction of chars removed after cleaning\n",
    "    features.append((len(token[0]) - len(token[2])) / float(len(token[0])))\n",
    "    \n",
    "    # 2. Editdistance bw original and clean token\n",
    "    features.append(float(editdistance.eval(token[0], token[2].lower())) / len(token[0]))\n",
    "    \n",
    "    # 3. First letter capitalised or not\n",
    "    if token[0][0].isupper():\n",
    "        features.append(1)\n",
    "    else:\n",
    "        features.append(0)\n",
    "\n",
    "    # 4. Percentage of capitalised letters\n",
    "    capCount = 0.\n",
    "    for ch in token[0][0]:\n",
    "        if ch.isupper():\n",
    "            capCount += 1.\n",
    "    features.append(capCount / len(token[0]))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "allTokens = []\n",
    "\n",
    "for tweet in allTweets:\n",
    "    for j in range(len(tweet)):\n",
    "        token = tweet[j]\n",
    "        \n",
    "        currFeature = probFeatureExtractor(token)\n",
    "        \n",
    "        if j == 0:\n",
    "            prevFeature = np.zeros_like(currFeature)\n",
    "        else:\n",
    "            prevFeature = probFeatureExtractor(tweet[j - 1])\n",
    "        \n",
    "        if j == (len(tweet) - 1):\n",
    "            nextFeature = np.zeros_like(currFeature)\n",
    "        else:\n",
    "            nextFeature = probFeatureExtractor(tweet[j + 1])\n",
    "        \n",
    "        otherFeatures = otherFeatureExtractor(token)\n",
    "        \n",
    "#         feature = np.concatenate((prevFeature, currFeature, nextFeature, otherFeatures))\n",
    "        feature = np.concatenate((currFeature, otherFeatures))\n",
    "        allTokens.append(token[:3])\n",
    "    \n",
    "        X.append(feature)\n",
    "        \n",
    "        if token[1] == 'hi':\n",
    "            y.append(0)\n",
    "        elif token[1] == 'en':\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "allTokens = np.array(allTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTestBounds = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidf = Sequential()\n",
    "\n",
    "lidf.add(Dense(256, input_shape = xTrain.shape[1:]))\n",
    "lidf.add(Activation('relu'))\n",
    "lidf.add(keras.layers.BatchNormalization())\n",
    "lidf.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "lidf.add(Dense(128))\n",
    "lidf.add(Activation('relu'))\n",
    "lidf.add(keras.layers.BatchNormalization())\n",
    "lidf.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "lidf.add(Dense(64))\n",
    "lidf.add(Activation('relu'))\n",
    "lidf.add(keras.layers.BatchNormalization())\n",
    "lidf.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "lidf.add(Dense(32))\n",
    "lidf.add(Activation('relu'))\n",
    "lidf.add(keras.layers.BatchNormalization())\n",
    "lidf.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "lidf.add(Dense(3))\n",
    "lidf.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fold 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11877 2643\n",
      "(11877, 158) (2643, 158) (2643, 3)\n"
     ]
    }
   ],
   "source": [
    "foldSize = int(0.2 * len(allTweets))\n",
    "\n",
    "trainLen, testLen = 0, 0\n",
    "marker = 0\n",
    "\n",
    "xTrain = []\n",
    "yTrain = []\n",
    "\n",
    "xTest = []\n",
    "yTest = []\n",
    "\n",
    "tokensTrain = []\n",
    "tokensTest  = []\n",
    "\n",
    "for tw in allTweets[ : foldSize * 4]:\n",
    "    trainLen += len(tw)\n",
    "    \n",
    "    for token in tw:\n",
    "        xTrain.append(X[marker].tolist())\n",
    "        yTrain.append(y[marker].tolist())\n",
    "        tokensTrain.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "        \n",
    "beg = marker\n",
    "for tw in allTweets[foldSize * 4 : foldSize * 5]:\n",
    "    testLen += len(tw)\n",
    "\n",
    "    for token in tw:\n",
    "        xTest.append(X[marker].tolist())\n",
    "        yTest.append(y[marker].tolist())\n",
    "        tokensTest.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "end = marker\n",
    "allTestBounds.append((beg, end))\n",
    "\n",
    "for tw in allTweets[foldSize * 5 : ]:\n",
    "    trainLen += len(tw)\n",
    "    \n",
    "    for token in tw:\n",
    "        xTrain.append(X[marker].tolist())\n",
    "        yTrain.append(y[marker].tolist())\n",
    "        tokensTrain.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "\n",
    "print trainLen, testLen\n",
    "\n",
    "xTrain = np.array(xTrain)\n",
    "yTrain = np.array(yTrain)\n",
    "\n",
    "xTest = np.array(xTest)\n",
    "yTest = np.array(yTest)\n",
    "\n",
    "tokensTrain = np.array(tokensTrain)\n",
    "tokensTest = np.array(tokensTest)\n",
    "\n",
    "print xTrain.shape, xTest.shape, tokensTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading trained weights\n",
    "lidf.load_weights('bestLidf_96_94_fold1.h5')\n",
    "opt = keras.optimizers.Adam(lr = 0.0005)\n",
    "lidf.compile(loss = 'categorical_crossentropy', optimizer = opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96      6529\n",
      "          1       0.94      0.93      0.94      4393\n",
      "          2       0.99      0.99      0.99      1034\n",
      "\n",
      "avg / total       0.95      0.95      0.95     11956\n",
      "\n",
      "95.3412512546\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.97      0.97      1518\n",
      "          1       0.94      0.96      0.95       872\n",
      "          2       0.99      1.00      1.00       174\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2564\n",
      "\n",
      "96.6068642746\n"
     ]
    }
   ],
   "source": [
    "trainPred = lidf.predict_classes(xTrain)\n",
    "print '\\n\\nTrain\\n\\n'\n",
    "print classification_report(y_pred = trainPred, y_true = yTrain)\n",
    "\n",
    "print accuracy_score(y_pred = trainPred, y_true = yTrain) * 100\n",
    "\n",
    "testPred  = lidf.predict_classes(xTest)\n",
    "print '\\n\\nTest\\n\\n'\n",
    "print classification_report(y_pred = testPred,  y_true = yTest)\n",
    "print accuracy_score(y_pred = testPred,  y_true = yTest) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11956 2564\n",
      "(11956, 158) (2564, 158) (2564, 3)\n"
     ]
    }
   ],
   "source": [
    "foldSize = int(0.2 * len(allTweets))\n",
    "\n",
    "trainLen, testLen = 0, 0\n",
    "marker = 0\n",
    "\n",
    "xTrain = []\n",
    "yTrain = []\n",
    "\n",
    "xTest = []\n",
    "yTest = []\n",
    "\n",
    "tokensTrain = []\n",
    "tokensTest  = []\n",
    "\n",
    "for tw in allTweets[ : foldSize * 3]:\n",
    "    trainLen += len(tw)\n",
    "    \n",
    "    for token in tw:\n",
    "        xTrain.append(X[marker].tolist())\n",
    "        yTrain.append(y[marker].tolist())\n",
    "        tokensTrain.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "        \n",
    "beg = marker\n",
    "for tw in allTweets[foldSize * 3 : foldSize * 4]:\n",
    "    testLen += len(tw)\n",
    "\n",
    "    for token in tw:\n",
    "        xTest.append(X[marker].tolist())\n",
    "        yTest.append(y[marker].tolist())\n",
    "        tokensTest.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "end = marker\n",
    "allTestBounds.append((beg, end))\n",
    "\n",
    "for tw in allTweets[foldSize * 4 : ]:\n",
    "    trainLen += len(tw)\n",
    "    \n",
    "    for token in tw:\n",
    "        xTrain.append(X[marker].tolist())\n",
    "        yTrain.append(y[marker].tolist())\n",
    "        tokensTrain.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "\n",
    "print trainLen, testLen\n",
    "\n",
    "xTrain = np.array(xTrain)\n",
    "yTrain = np.array(yTrain)\n",
    "\n",
    "xTest = np.array(xTest)\n",
    "yTest = np.array(yTest)\n",
    "\n",
    "tokensTrain = np.array(tokensTrain)\n",
    "tokensTest = np.array(tokensTest)\n",
    "\n",
    "print xTrain.shape, xTest.shape, tokensTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.96      6328\n",
      "          1       0.95      0.93      0.94      4057\n",
      "          2       0.98      0.99      0.98       939\n",
      "\n",
      "avg / total       0.96      0.96      0.96     11324\n",
      "\n",
      "95.6993995055\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97      1719\n",
      "          1       0.97      0.92      0.95      1208\n",
      "          2       0.99      0.99      0.99       269\n",
      "\n",
      "avg / total       0.96      0.96      0.96      3196\n",
      "\n",
      "96.1827284105\n"
     ]
    }
   ],
   "source": [
    "# Loading trained weights\n",
    "lidf.load_weights('bestLidf_96_94_fold2.h5')\n",
    "opt = keras.optimizers.Adam(lr = 0.0005)\n",
    "lidf.compile(loss = 'categorical_crossentropy', optimizer = opt)\n",
    "\n",
    "trainPred = lidf.predict_classes(xTrain)\n",
    "print '\\n\\nTrain\\n\\n'\n",
    "print classification_report(y_pred = trainPred, y_true = yTrain)\n",
    "\n",
    "print accuracy_score(y_pred = trainPred, y_true = yTrain) * 100\n",
    "\n",
    "testPred  = lidf.predict_classes(xTest)\n",
    "print '\\n\\nTest\\n\\n'\n",
    "print classification_report(y_pred = testPred,  y_true = yTest)\n",
    "print accuracy_score(y_pred = testPred,  y_true = yTest) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11550 2970\n",
      "(11550, 158) (2970, 158) (2970, 3)\n"
     ]
    }
   ],
   "source": [
    "foldSize = int(0.2 * len(allTweets))\n",
    "\n",
    "trainLen, testLen = 0, 0\n",
    "marker = 0\n",
    "\n",
    "xTrain = []\n",
    "yTrain = []\n",
    "\n",
    "xTest = []\n",
    "yTest = []\n",
    "\n",
    "tokensTrain = []\n",
    "tokensTest  = []\n",
    "\n",
    "for tw in allTweets[ : foldSize * 2]:\n",
    "    trainLen += len(tw)\n",
    "    \n",
    "    for token in tw:\n",
    "        xTrain.append(X[marker].tolist())\n",
    "        yTrain.append(y[marker].tolist())\n",
    "        tokensTrain.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "\n",
    "beg = marker\n",
    "for tw in allTweets[foldSize * 2 : foldSize * 3]:\n",
    "    testLen += len(tw)\n",
    "\n",
    "    for token in tw:\n",
    "        xTest.append(X[marker].tolist())\n",
    "        yTest.append(y[marker].tolist())\n",
    "        tokensTest.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "end = marker\n",
    "allTestBounds.append((beg, end))\n",
    "\n",
    "for tw in allTweets[foldSize * 3 : ]:\n",
    "    trainLen += len(tw)\n",
    "    \n",
    "    for token in tw:\n",
    "        xTrain.append(X[marker].tolist())\n",
    "        yTrain.append(y[marker].tolist())\n",
    "        tokensTrain.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "\n",
    "print trainLen, testLen\n",
    "\n",
    "xTrain = np.array(xTrain)\n",
    "yTrain = np.array(yTrain)\n",
    "\n",
    "xTest = np.array(xTest)\n",
    "yTest = np.array(yTest)\n",
    "\n",
    "tokensTrain = np.array(tokensTrain)\n",
    "tokensTest = np.array(tokensTest)\n",
    "\n",
    "print xTrain.shape, xTest.shape, tokensTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.97      0.96      6328\n",
      "          1       0.96      0.92      0.94      4057\n",
      "          2       0.99      0.97      0.98       939\n",
      "\n",
      "avg / total       0.95      0.95      0.95     11324\n",
      "\n",
      "95.4609678559\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      1719\n",
      "          1       0.98      0.92      0.95      1208\n",
      "          2       0.99      0.99      0.99       269\n",
      "\n",
      "avg / total       0.96      0.96      0.96      3196\n",
      "\n",
      "96.2140175219\n"
     ]
    }
   ],
   "source": [
    "# Loading trained weights\n",
    "lidf.load_weights('bestLidf_96_92_fold3.h5')\n",
    "opt = keras.optimizers.Adam(lr = 0.0005)\n",
    "lidf.compile(loss = 'categorical_crossentropy', optimizer = opt)\n",
    "\n",
    "trainPred = lidf.predict_classes(xTrain)\n",
    "print '\\n\\nTrain\\n\\n'\n",
    "print classification_report(y_pred = trainPred, y_true = yTrain)\n",
    "\n",
    "print accuracy_score(y_pred = trainPred, y_true = yTrain) * 100\n",
    "\n",
    "testPred  = lidf.predict_classes(xTest)\n",
    "print '\\n\\nTest\\n\\n'\n",
    "print classification_report(y_pred = testPred,  y_true = yTest)\n",
    "print accuracy_score(y_pred = testPred,  y_true = yTest) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11324 3196\n",
      "(11324, 158) (3196, 158) (3196, 3)\n"
     ]
    }
   ],
   "source": [
    "foldSize = int(0.2 * len(allTweets))\n",
    "\n",
    "trainLen, testLen = 0, 0\n",
    "marker = 0\n",
    "\n",
    "xTrain = []\n",
    "yTrain = []\n",
    "\n",
    "xTest = []\n",
    "yTest = []\n",
    "\n",
    "tokensTrain = []\n",
    "tokensTest  = []\n",
    "\n",
    "for tw in allTweets[ : foldSize * 1]:\n",
    "    trainLen += len(tw)\n",
    "    \n",
    "    for token in tw:\n",
    "        xTrain.append(X[marker].tolist())\n",
    "        yTrain.append(y[marker].tolist())\n",
    "        tokensTrain.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "        \n",
    "beg = marker\n",
    "for tw in allTweets[foldSize * 1 : foldSize * 2]:\n",
    "    testLen += len(tw)\n",
    "\n",
    "    for token in tw:\n",
    "        xTest.append(X[marker].tolist())\n",
    "        yTest.append(y[marker].tolist())\n",
    "        tokensTest.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "end = marker\n",
    "allTestBounds.append((beg, end))\n",
    "\n",
    "for tw in allTweets[foldSize * 2 : ]:\n",
    "    trainLen += len(tw)\n",
    "    \n",
    "    for token in tw:\n",
    "        xTrain.append(X[marker].tolist())\n",
    "        yTrain.append(y[marker].tolist())\n",
    "        tokensTrain.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "\n",
    "print trainLen, testLen\n",
    "\n",
    "xTrain = np.array(xTrain)\n",
    "yTrain = np.array(yTrain)\n",
    "\n",
    "xTest = np.array(xTest)\n",
    "yTest = np.array(yTest)\n",
    "\n",
    "tokensTrain = np.array(tokensTrain)\n",
    "tokensTest = np.array(tokensTest)\n",
    "\n",
    "print xTrain.shape, xTest.shape, tokensTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97      6328\n",
      "          1       0.96      0.94      0.95      4057\n",
      "          2       0.99      1.00      0.99       939\n",
      "\n",
      "avg / total       0.96      0.96      0.96     11324\n",
      "\n",
      "96.3440480396\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.95      1719\n",
      "          1       0.94      0.89      0.91      1208\n",
      "          2       0.93      0.94      0.94       269\n",
      "\n",
      "avg / total       0.93      0.93      0.93      3196\n",
      "\n",
      "93.3979974969\n"
     ]
    }
   ],
   "source": [
    "# Loading trained weights\n",
    "lidf.load_weights('bestLidf_96_93_fold4.h5')\n",
    "opt = keras.optimizers.Adam(lr = 0.0005)\n",
    "lidf.compile(loss = 'categorical_crossentropy', optimizer = opt)\n",
    "\n",
    "trainPred = lidf.predict_classes(xTrain)\n",
    "print '\\n\\nTrain\\n\\n'\n",
    "print classification_report(y_pred = trainPred, y_true = yTrain)\n",
    "\n",
    "print accuracy_score(y_pred = trainPred, y_true = yTrain) * 100\n",
    "\n",
    "testPred  = lidf.predict_classes(xTest)\n",
    "print '\\n\\nTest\\n\\n'\n",
    "print classification_report(y_pred = testPred,  y_true = yTest)\n",
    "print accuracy_score(y_pred = testPred,  y_true = yTest) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11382 3138\n",
      "(11382, 158) (3138, 158) (3138, 3)\n"
     ]
    }
   ],
   "source": [
    "foldSize = int(0.2 * len(allTweets))\n",
    "\n",
    "trainLen, testLen = 0, 0\n",
    "marker = 0\n",
    "\n",
    "xTrain = []\n",
    "yTrain = []\n",
    "\n",
    "xTest = []\n",
    "yTest = []\n",
    "\n",
    "tokensTrain = []\n",
    "tokensTest  = []\n",
    "\n",
    "for tw in allTweets[ : foldSize * 0]:\n",
    "    trainLen += len(tw)\n",
    "    \n",
    "    for token in tw:\n",
    "        xTrain.append(X[marker].tolist())\n",
    "        yTrain.append(y[marker].tolist())\n",
    "        tokensTrain.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "        \n",
    "beg = marker        \n",
    "for tw in allTweets[foldSize * 0 : foldSize * 1]:\n",
    "    testLen += len(tw)\n",
    "\n",
    "    for token in tw:\n",
    "        xTest.append(X[marker].tolist())\n",
    "        yTest.append(y[marker].tolist())\n",
    "        tokensTest.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "end = marker\n",
    "allTestBounds.append((beg, end))\n",
    "\n",
    "for tw in allTweets[foldSize * 1 : ]:\n",
    "    trainLen += len(tw)\n",
    "    \n",
    "    for token in tw:\n",
    "        xTrain.append(X[marker].tolist())\n",
    "        yTrain.append(y[marker].tolist())\n",
    "        tokensTrain.append(allTokens[marker].tolist())\n",
    "        marker += 1\n",
    "\n",
    "print trainLen, testLen\n",
    "\n",
    "xTrain = np.array(xTrain)\n",
    "yTrain = np.array(yTrain)\n",
    "\n",
    "xTest = np.array(xTest)\n",
    "yTest = np.array(yTest)\n",
    "\n",
    "tokensTrain = np.array(tokensTrain)\n",
    "tokensTest = np.array(tokensTest)\n",
    "\n",
    "print xTrain.shape, xTest.shape, tokensTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97      6419\n",
      "          1       0.97      0.92      0.95      4063\n",
      "          2       0.99      1.00      0.99       900\n",
      "\n",
      "avg / total       0.96      0.96      0.96     11382\n",
      "\n",
      "96.2660340889\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94      1628\n",
      "          1       0.94      0.89      0.91      1202\n",
      "          2       0.97      0.90      0.94       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      3138\n",
      "\n",
      "93.1485022307\n"
     ]
    }
   ],
   "source": [
    "# Loading trained weights\n",
    "lidf.load_weights('bestLidf_96_93_fold5.h5')\n",
    "opt = keras.optimizers.Adam(lr = 0.0005)\n",
    "lidf.compile(loss = 'categorical_crossentropy', optimizer = opt)\n",
    "\n",
    "trainPred = lidf.predict_classes(xTrain)\n",
    "print '\\n\\nTrain\\n\\n'\n",
    "print classification_report(y_pred = trainPred, y_true = yTrain)\n",
    "\n",
    "print accuracy_score(y_pred = trainPred, y_true = yTrain) * 100\n",
    "\n",
    "testPred  = lidf.predict_classes(xTest)\n",
    "print '\\n\\nTest\\n\\n'\n",
    "print classification_report(y_pred = testPred,  y_true = yTest)\n",
    "print accuracy_score(y_pred = testPred,  y_true = yTest) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating overall test errors across folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILENAMES\n",
    "models = ['bestLidf_96_94_fold1.h5', 'bestLidf_96_94_fold2.h5', 'bestLidf_96_92_fold3.h5', 'bestLidf_96_93_fold4.h5', 'bestLidf_96_93_fold5.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13937 13937\n"
     ]
    }
   ],
   "source": [
    "yTest = []\n",
    "yPred = []\n",
    "\n",
    "for i in range(5):\n",
    "    xTest = X[allTestBounds[i][0] : allTestBounds[i][1]]\n",
    "    lidf.load_weights(models[i])\n",
    "    \n",
    "    yPred += lidf.predict_classes(xTest, batch_size = 1024).tolist()\n",
    "    yTest += y[allTestBounds[i][0] : allTestBounds[i][1]].tolist()\n",
    "    \n",
    "print len(yTest), len(yPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9546    0.9681    0.9613      7932\n",
      "          1     0.9459    0.9225    0.9341      4932\n",
      "          2     0.9769    0.9860    0.9814      1073\n",
      "\n",
      "avg / total     0.9533    0.9534    0.9532     13937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_pred = yPred, y_true = yTest, digits = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953361555572\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(y_pred = yPred, y_true = yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11868, 14511),\n",
       " (9304, 11868),\n",
       " (9304, 11868),\n",
       " (6334, 9304),\n",
       " (3138, 6334),\n",
       " (0, 3138)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allTestBounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
